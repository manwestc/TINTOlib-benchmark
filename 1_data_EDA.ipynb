{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032de110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd3c264",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac1675",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1213b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def load_tabular_dataset(name, info):\n",
    "    \"\"\"\n",
    "    Loads any dataset given its name, does automatic EDA based on feature meaning\n",
    "    (categorical/numerical detected from JSON), and saves the EDA analysis as a .txt file.\n",
    "    \n",
    "    Expected:\n",
    "    - Dataset CSV should be located in data/{name}.csv\n",
    "    - Dataset JSON should be located in data/{name}.json\n",
    "    - The label column must be the last column.\n",
    "    \"\"\"\n",
    "    dataset_path = os.path.join(\"data\", f\"{name}.csv\")\n",
    "    json_path = os.path.join(\"data\", f\"{info}.json\")\n",
    "    if not os.path.exists(dataset_path):\n",
    "        raise FileNotFoundError(f\"Dataset not found: {dataset_path}\")\n",
    "    if not os.path.exists(json_path):\n",
    "        raise FileNotFoundError(f\"Metadata JSON not found: {json_path}\")\n",
    "\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    # Load dataset info (feature types)\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        dataset_info = json.load(f)\n",
    "    categorical_cols = list(dataset_info[\"cat_feature_intro\"].keys())\n",
    "    numerical_cols = list(dataset_info[\"num_feature_intro\"].keys())\n",
    "\n",
    "    # Create EDA text\n",
    "    eda_report = []\n",
    "    eda_report.append(f\"üìä Dataset: {name}\\n\")\n",
    "    eda_report.append(f\"Shape: {df.shape}\\n\")\n",
    "\n",
    "    eda_report.append(\"\\nColumns:\")\n",
    "    eda_report.append(str(df.columns.tolist()))\n",
    "\n",
    "    eda_report.append(\"\\n\\nFirst 5 rows:\")\n",
    "    eda_report.append(str(df.head()))\n",
    "\n",
    "    # Missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    total_missing = missing_values.sum()\n",
    "    eda_report.append(\"\\n\\nMissing values per column:\")\n",
    "    eda_report.append(str(missing_values))\n",
    "\n",
    "    eda_report.append(\"\\n\\nCategorical columns:\")\n",
    "    eda_report.append(str(categorical_cols))\n",
    "\n",
    "    eda_report.append(\"\\n\\nNumerical columns:\")\n",
    "    eda_report.append(str(numerical_cols))\n",
    "\n",
    "    label_column = df.columns[-1]\n",
    "    eda_report.append(f\"\\n\\n‚úÖ Assuming label column: '{label_column}'\")\n",
    "\n",
    "    eda_report.append(\"\\n\\nClass distribution (if classification):\")\n",
    "    eda_report.append(str(df[label_column].value_counts(dropna=False)))\n",
    "\n",
    "    # Check for class imbalance (only if classification: discrete target)\n",
    "    value_counts = df[label_column].value_counts()\n",
    "    if pd.api.types.is_integer_dtype(df[label_column]) or df[label_column].nunique() < 20:\n",
    "        majority_class = value_counts.iloc[0]\n",
    "        minority_class = value_counts.iloc[-1]\n",
    "        imbalance_ratio = majority_class / minority_class if minority_class > 0 else float('inf')\n",
    "\n",
    "        eda_report.append(\"\\n\\n‚öñÔ∏è Balance Check:\")\n",
    "        eda_report.append(f\"- Number of classes: {df[label_column].nunique()}\")\n",
    "        eda_report.append(f\"- Majority class count: {majority_class}\")\n",
    "        eda_report.append(f\"- Minority class count: {minority_class}\")\n",
    "        eda_report.append(f\"- Imbalance ratio (majority/minority): {imbalance_ratio:.2f}\")\n",
    "\n",
    "        if imbalance_ratio > 1.5:\n",
    "            eda_report.append(\"üö® Warning: Dataset may be imbalanced!\")\n",
    "        else:\n",
    "            eda_report.append(\"‚úÖ Class distribution looks balanced.\")\n",
    "\n",
    "    # --- New: Missing counts ---\n",
    "    num_categorical_missing = missing_values[categorical_cols].sum()\n",
    "    num_numerical_missing = missing_values[numerical_cols].sum()\n",
    "    eda_report.append(\"\\n\\nüîé Missing Value Summary:\")\n",
    "    eda_report.append(f\"- Missing values in categorical features: {num_categorical_missing}\")\n",
    "    eda_report.append(f\"- Missing values in numerical features: {num_numerical_missing}\")\n",
    "    eda_report.append(f\"- Total missing values: {total_missing}\")\n",
    "    eda_report.append(f\"- Overall missing rate: {total_missing / df.size:.2%}\")\n",
    "\n",
    "    if total_missing > 0:\n",
    "        eda_report.append(\"\\n‚ö†Ô∏è Warning: Dataset has missing values!\")\n",
    "\n",
    "    if len(categorical_cols) > 0:\n",
    "        eda_report.append(\"\\n‚ö° Info: Dataset has categorical features!\")\n",
    "\n",
    "    # --- Imputation suggestions ---\n",
    "    eda_report.append(\"\\n\\nüõ† Imputation Suggestions:\")\n",
    "\n",
    "    # Numerical features: check skewness\n",
    "    skewness = df[numerical_cols].skew()\n",
    "    for col in numerical_cols:\n",
    "        if missing_values[col] > 0:\n",
    "            skew = skewness[col]\n",
    "            if abs(skew) < 0.5:\n",
    "                suggestion = \"mean imputation (symmetric)\"\n",
    "            else:\n",
    "                suggestion = \"median imputation (skewed/long tail)\"\n",
    "            eda_report.append(f\"- Feature '{col}': {suggestion} (skewness = {skew:.2f})\")\n",
    "\n",
    "    # Categorical features: suggest adding new category if missing\n",
    "    for col in categorical_cols:\n",
    "        if missing_values[col] > 0:\n",
    "            eda_report.append(f\"- Feature '{col}': add a new category for missing values (e.g., 'Missing')\")\n",
    "\n",
    "    # Save EDA report\n",
    "    eda_save_path = os.path.join(\"data\", f\"{name}_EDA.txt\")\n",
    "    with open(eda_save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(eda_report))\n",
    "\n",
    "    print(f\"\\n‚úÖ EDA analysis saved to {eda_save_path}\")\n",
    "\n",
    "    # Separate features and label\n",
    "    X = df.drop(columns=[label_column])\n",
    "    y = df[label_column]\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eb14c1-385b-44a3-a12c-bd056116301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "task_type=\"Binary\" # Regression, Binary, Multiclass\n",
    "# Correct base directory\n",
    "base_dir = os.path.join(\"data\", task_type)\n",
    "\n",
    "# Loop through all subdirectories inside data/Regression/\n",
    "for dataset_name in os.listdir(base_dir):\n",
    "    dataset_path = os.path.join(base_dir, dataset_name)\n",
    "\n",
    "    # Skip non-directory files\n",
    "    if not os.path.isdir(dataset_path):\n",
    "        continue\n",
    "\n",
    "    csv_path = os.path.join(dataset_path, f\"{dataset_name}.csv\")\n",
    "    json_path = os.path.join(dataset_path, \"info.json\")\n",
    "\n",
    "    if os.path.exists(csv_path) and os.path.exists(json_path):\n",
    "        print(f\"\\nüöÄ Processing dataset: {dataset_name}\")\n",
    "        try:\n",
    "            X, y = load_tabular_dataset(\n",
    "                f\"{task_type}/{dataset_name}/{dataset_name}\",\n",
    "                f\"{task_type}/{dataset_name}/info\"\n",
    "            )\n",
    "            print(f\"‚úÖ Finished: {dataset_name} | X shape: {X.shape} | y shape: {y.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {dataset_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Skipping {dataset_name} ‚Äî missing .csv or info.json file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971e49a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9daebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_dataset(\n",
    "    name: str,\n",
    "    strategy_map: dict,  # {\"col1\": \"mean\", \"col2\": \"median\", \"col3\": \"constant\"}\n",
    "    cat_fill_value: str = '___null___',\n",
    "    save_cleaned: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess dataset by applying user-defined imputation strategies.\n",
    "\n",
    "    Args:\n",
    "    - name: dataset name (without .csv)\n",
    "    - strategy_map: dict mapping feature names -> strategy ('mean', 'median', 'constant')\n",
    "    - cat_fill_value: value used if strategy == 'constant'\n",
    "    - save_cleaned: whether to save the cleaned dataset to disk\n",
    "\n",
    "    Returns:\n",
    "    - X (features), y (target)\n",
    "    \"\"\"\n",
    "    dataset_path = os.path.join(\"data\", f\"{name}.csv\")\n",
    "    if not os.path.exists(dataset_path):\n",
    "        raise FileNotFoundError(f\"Dataset not found: {dataset_path}\")\n",
    "\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    # Separate label\n",
    "    label_column = df.columns[-1]\n",
    "    X = df.drop(columns=[label_column])\n",
    "    y = df[label_column]\n",
    "\n",
    "    # Apply strategy per column\n",
    "    for col, strategy in strategy_map.items():\n",
    "        if col not in X.columns:\n",
    "            print(f\"‚ö†Ô∏è Warning: Column {col} not in dataset, skipping...\")\n",
    "            continue\n",
    "\n",
    "        if strategy == \"mean\":\n",
    "            X[col] = X[col].fillna(X[col].mean())\n",
    "        elif strategy == \"median\":\n",
    "            X[col] = X[col].fillna(X[col].median())\n",
    "        elif strategy == \"constant\":\n",
    "            X[col] = X[col].fillna(cat_fill_value)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown strategy '{strategy}' for column '{col}'\")\n",
    "\n",
    "    # Recombine\n",
    "    cleaned_df = pd.concat([X, y], axis=1)\n",
    "\n",
    "    if save_cleaned:\n",
    "        cleaned_path = os.path.join(\"data\", f\"{name}_cleaned.csv\")\n",
    "        cleaned_df.to_csv(cleaned_path, index=False)\n",
    "        print(f\"‚úÖ Cleaned dataset saved to {cleaned_path}\")\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b525b32",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Adult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3887ae9",
   "metadata": {},
   "source": [
    "Imputation Suggestions:\n",
    "- Feature 'workclass': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'occupation': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'native-country': add a new category for missing values (e.g., 'Missing')\n",
    "\n",
    "Strategy:\n",
    "- Fill missing categorical values with a new category\n",
    "- No action needed for numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1973674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_map = {\n",
    "    \"workclass\": \"constant\",\n",
    "    \"occupation\": \"constant\",\n",
    "    \"native-country\": \"constant\",\n",
    "}\n",
    "\n",
    "X, y = preprocess_dataset(\"Binary/adult/adult\", strategy_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7593424c-37b2-4fda-88ce-49fb774528e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Jm1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7be75f-b943-47df-89d5-966202ae47a7",
   "metadata": {},
   "source": [
    "Imputation Suggestions:\n",
    "- Feature 'uniq_Op': median imputation (skewed/long tail) (skewness = 14.57)\n",
    "- Feature 'uniq_Opnd': median imputation (skewed/long tail) (skewness = 13.65)\n",
    "- Feature 'total_Op': median imputation (skewed/long tail) (skewness = 11.29)\n",
    "- Feature 'total_Opnd': median imputation (skewed/long tail) (skewness = 9.50)\n",
    "- Feature 'branchCount': median imputation (skewed/long tail) (skewness = 11.63)\n",
    "\n",
    "Strategy:\n",
    "- Fill missing categorical values with a new category\n",
    "- No action needed for numerical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf9775-da14-4072-a052-55749c56ca6a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "strategy_map = {\n",
    "    \"uniq_Op\": \"median\",       # skewness = 14.57\n",
    "    \"uniq_Opnd\": \"median\",     # skewness = 13.65\n",
    "    \"total_Op\": \"median\",      # skewness = 11.29\n",
    "    \"total_Opnd\": \"median\",    # skewness = 9.50\n",
    "    \"branchCount\": \"median\"    # skewness = 11.63\n",
    "}\n",
    "\n",
    "X, y = preprocess_dataset(\"Binary/jm1/jm1\", strategy_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f453f15c-555d-40a0-b21e-69a1963d247b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## credit-aproval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa366b-5810-461a-acb7-c9d949e49c88",
   "metadata": {},
   "source": [
    "Imputation Suggestions:\n",
    "- Feature 'A2': median imputation (skewed/long tail) (skewness = 1.15)\n",
    "- Feature 'A14': median imputation (skewed/long tail) (skewness = 2.72)\n",
    "- Feature 'A1': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'A4': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'A5': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'A6': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'A7': add a new category for missing values (e.g., 'Missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2b01b4-9295-4b77-8bef-fbc726b35cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strategy_map = {\n",
    "    \"A2\": \"median\",   # skewness = 1.15\n",
    "    \"A14\": \"median\",  # skewness = 2.72\n",
    "    \"A1\": \"constant\", # add category for missing values\n",
    "    \"A4\": \"constant\", # add category for missing values\n",
    "    \"A5\": \"constant\", # add category for missing values\n",
    "    \"A6\": \"constant\", # add category for missing values\n",
    "    \"A7\": \"constant\"  # add category for missing values\n",
    "}\n",
    "\n",
    "X, y = preprocess_dataset(\"Binary/credit-approval/credit-approval\", strategy_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea33c26-797f-4478-be69-46858e082310",
   "metadata": {},
   "source": [
    "## Moneyball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a912d13-23fa-40de-9b7e-39ec7784c7d2",
   "metadata": {},
   "source": [
    "Imputation Suggestions:\n",
    "- Feature 'OOBP': mean imputation (symmetric) (skewness = 0.20)\n",
    "- Feature 'OSLG': mean imputation (symmetric) (skewness = 0.12)\n",
    "- Feature 'RankSeason': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'RankPlayoffs': add a new category for missing values (e.g., 'Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdc39c6-d3dc-4418-bd47-93ebd568f3d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strategy_map = {\n",
    "    \"OOBP\": \"median\", \n",
    "    \"OSLG\": \"median\", \n",
    "    \"RankSeason\": \"constant\", # add category for missing values\n",
    "    \"RankPlayoffs\": \"constant\", # add category for missing values\n",
    "}\n",
    "\n",
    "X, y = preprocess_dataset(\"Regression/Moneyball/Moneyball\", strategy_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca95436-806f-46fb-8cb3-3cbed94a73fd",
   "metadata": {},
   "source": [
    "## credit-aproval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981b590-2fea-485d-88a0-49fb95a43818",
   "metadata": {},
   "source": [
    "Imputation Suggestions:\n",
    "- Feature 'A2': median imputation (skewed/long tail) (skewness = 1.15)\n",
    "- Feature 'A14': median imputation (skewed/long tail) (skewness = 2.72)\n",
    "- Feature 'A1': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'A4': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'A5': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'A6': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'A7': add a new category for missing values (e.g., 'Missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ac340-e019-455e-a402-241ca612b43d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strategy_map = {\n",
    "    \"A2\": \"median\",   # skewness = 1.15\n",
    "    \"A14\": \"median\",  # skewness = 2.72\n",
    "    \"A1\": \"constant\", # add category for missing values\n",
    "    \"A4\": \"constant\", # add category for missing values\n",
    "    \"A5\": \"constant\", # add category for missing values\n",
    "    \"A6\": \"constant\", # add category for missing values\n",
    "    \"A7\": \"constant\"  # add category for missing values\n",
    "}\n",
    "\n",
    "X, y = preprocess_dataset(\"Binary/credit-approval/credit-approval\", strategy_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d9aeb-ebe9-4d8b-b19f-068858808c4c",
   "metadata": {},
   "source": [
    "## credit-aproval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09965f3-70c7-4295-b4ed-8ae78161046c",
   "metadata": {},
   "source": [
    "Imputation Suggestions:\n",
    "- Feature 'A2': median imputation (skewed/long tail) (skewness = 1.15)\n",
    "- Feature 'A14': median imputation (skewed/long tail) (skewness = 2.72)\n",
    "- Feature 'A1': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'A4': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'A5': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'A6': add a new category for missing values (e.g., 'Missing')\n",
    "- Feature 'A7': add a new category for missing values (e.g., 'Missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc0b96-3bb3-45c7-b87a-3e1d7076a51d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strategy_map = {\n",
    "    \"A2\": \"median\",   # skewness = 1.15\n",
    "    \"A14\": \"median\",  # skewness = 2.72\n",
    "    \"A1\": \"constant\", # add category for missing values\n",
    "    \"A4\": \"constant\", # add category for missing values\n",
    "    \"A5\": \"constant\", # add category for missing values\n",
    "    \"A6\": \"constant\", # add category for missing values\n",
    "    \"A7\": \"constant\"  # add category for missing values\n",
    "}\n",
    "\n",
    "X, y = preprocess_dataset(\"Binary/credit-approval/credit-approval\", strategy_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
