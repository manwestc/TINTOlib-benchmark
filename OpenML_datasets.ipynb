{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c0a5a-e58f-4530-99e2-69fd7d0416c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "def _nice_round(v: float) -> int:\n",
    "    \"\"\"Snap to human-friendly thresholds like 500, 1k, 2k, 5k, 10k, 30k, ...\"\"\"\n",
    "    if v <= 0:\n",
    "        return 500\n",
    "    base = 10 ** np.floor(np.log10(v))\n",
    "    m = v / base\n",
    "    if m < 1.5:\n",
    "        step = 1\n",
    "    elif m < 3.5:\n",
    "        step = 2\n",
    "    elif m < 7.5:\n",
    "        step = 5\n",
    "    else:\n",
    "        step = 10\n",
    "    return int(step * base)\n",
    "\n",
    "def compute_unified_size_bins(\n",
    "    suites=(\"OpenML-CC18\", 353),    # CC-18 (classification) + CTR23 (regression)\n",
    "    quantiles=(0.33, 0.66),         # tertiles on log10(#instances)\n",
    "    min_small=0,                    # optional floor for the small/medium cut\n",
    "    return_details=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute *unified* small/medium/large cutoffs from log10(#instances)\n",
    "    over the union of the provided OpenML suites, then round to nice thresholds.\n",
    "    Returns (bins, labels, details) if return_details else (bins, labels).\n",
    "    \"\"\"\n",
    "    # Collect dataset ids from all suites\n",
    "    dids = set()\n",
    "    for suite_id in suites:\n",
    "        suite = openml.study.get_suite(suite_id)\n",
    "        for tid in suite.tasks:\n",
    "            dids.add(openml.tasks.get_task(tid, download_data=False).dataset_id)\n",
    "    dids = list(dids)\n",
    "\n",
    "    # Pull #instances\n",
    "    meta = openml.datasets.list_datasets(data_id=dids, output_format=\"dataframe\")\n",
    "    if \"NumberOfInstances\" not in meta.columns:\n",
    "        raise RuntimeError(\"OpenML response missing NumberOfInstances.\")\n",
    "    n = pd.to_numeric(meta[\"NumberOfInstances\"], errors=\"coerce\").dropna().values\n",
    "    n = n[n > 0]\n",
    "    if len(n) < 10:\n",
    "        raise RuntimeError(\"Too few datasets to compute stable quantiles.\")\n",
    "\n",
    "    # Quantiles on log10(n) → round to nice thresholds\n",
    "    x = np.log10(n)\n",
    "    q1, q2 = np.quantile(x, quantiles)\n",
    "    b1 = max(min_small, _nice_round(10 ** q1))\n",
    "    b2 = _nice_round(10 ** q2)\n",
    "    if b2 <= b1:  # ensure monotonicity\n",
    "        b2 = _nice_round(b1 * 3.1)\n",
    "\n",
    "    bins   = [b1, b2, np.inf]\n",
    "    labels = [\"small\", \"medium\", \"large\"]\n",
    "\n",
    "    note = (f\"We defined small/medium/large by tertiles of log10(#instances) computed \"\n",
    "            f\"on the combined CC-18 and CTR23 suites, then rounded to convenient \"\n",
    "            f\"thresholds (small ≤ {b1:,}, medium ≤ {b2:,}, large > {b2:,}). \"\n",
    "            f\"These cutoffs were fixed prior to running experiments.\")\n",
    "\n",
    "    if return_details:\n",
    "        return bins, labels, {\n",
    "            \"n_datasets\": int(len(n)),\n",
    "            \"quantiles_log10\": (float(q1), float(q2)),\n",
    "            \"raw_thresholds\": (float(10**q1), float(10**q2)),\n",
    "            \"rounded_thresholds\": (int(b1), int(b2)),\n",
    "            \"paper_note\": note,\n",
    "        }\n",
    "    return bins, labels\n",
    "\n",
    "def annotate_size_bin(df: pd.DataFrame, bins, labels, col=\"NumberOfInstances\", out_col=\"size_bin\"):\n",
    "    \"\"\"Add a 'size_bin' categorical column to a metadata DF using unified bins.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[out_col] = pd.cut(pd.to_numeric(df[col], errors=\"coerce\"),\n",
    "                         bins=[-np.inf, bins[0], bins[1], np.inf],\n",
    "                         labels=labels, right=True, include_lowest=True)\n",
    "    return df\n",
    "\n",
    "# --- Example (use once at the start of your pipeline) ---\n",
    "if __name__ == \"__main__\":\n",
    "    bins, labels, info = compute_unified_size_bins(return_details=True)\n",
    "    print(\"UNIFIED SIZE_BINS:\", bins)\n",
    "    print(\"UNIFIED SIZE_LABELS:\", labels)\n",
    "    print(info[\"paper_note\"])\n",
    "    # Use `annotate_size_bin(meta_df, bins, labels)` for both CC-18 and CTR23 tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b788fc-085b-466b-848e-004e7b64a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openml pandas numpy\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from collections import OrderedDict, defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "\n",
    "# ============================ Config ==========================================\n",
    "SIZE_BINS = [0, 2000, 10000, np.inf]\n",
    "SIZE_LABELS = [\"small\", \"medium\", \"large\"]\n",
    "CAT_FRAC_THRESHOLD = 0.6  # >= → high_categorical\n",
    "\n",
    "\n",
    "# ============================ Small helpers ===================================\n",
    "def _ensure_columns(df, cols, fill=np.nan):\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = fill\n",
    "    return df\n",
    "\n",
    "def _safe_num(s):\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def _compute_missing(df: pd.DataFrame) -> Tuple[int, float]:\n",
    "    missing_cells = int(df.isna().sum().sum())\n",
    "    total_cells = int(df.shape[0] * df.shape[1]) if df.size else 0\n",
    "    missing_pct = float(missing_cells / total_cells) if total_cells > 0 else 0.0\n",
    "    return missing_cells, missing_pct\n",
    "\n",
    "def _safe_imbalance(y: pd.Series) -> float | None:\n",
    "    try:\n",
    "        vc = y.value_counts(dropna=False)\n",
    "        if len(vc) < 2:\n",
    "            return None\n",
    "        maj, minc = vc.max(), vc.min()\n",
    "        return float(maj / minc) if minc > 0 else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _task_type_from_classes(n_classes: int | float | None) -> str:\n",
    "    if pd.isna(n_classes):\n",
    "        return \"unknown\"\n",
    "    return \"binary\" if int(n_classes) == 2 else \"multiclass\"\n",
    "\n",
    "def _openml_page_url(did: int) -> str:\n",
    "    return f\"https://www.openml.org/d/{did}\"\n",
    "\n",
    "def _file_safe_exact(name: str) -> str:\n",
    "    # Keep exact appearance; only neutralize path-breaking chars.\n",
    "    if os.sep in name:\n",
    "        name = name.replace(os.sep, \"⧸\")\n",
    "    return name.replace(\":\", \"：\")\n",
    "\n",
    "def _openml_download_url_placeholder(did: int, dataset_name: str) -> str:\n",
    "    # A stable placeholder like your example (OpenML uses a file id internally, but this works as a readable reference).\n",
    "    fname = re.sub(r\"[^\\w\\-.]\", \"_\", dataset_name.strip())\n",
    "    return f\"https://api.openml.org/data/v1/download/{did}/{fname}.arff\"\n",
    "\n",
    "def _make_task_intro(dataset, did: int, dataset_name: str) -> str:\n",
    "    # Compose a markdown block similar to your example\n",
    "    creators = dataset.creator if isinstance(dataset.creator, str) else (\n",
    "        \", \".join(dataset.creator) if dataset.creator else \"Unknown\"\n",
    "    )\n",
    "    openml_page = _openml_page_url(did)\n",
    "    original = getattr(dataset, \"original_data_url\", None)\n",
    "    original_md = f\"[Original]({original})\" if original else \"[Original](N/A)\"\n",
    "    source_md = f\"[OpenML]({openml_page}) · {original_md}\"\n",
    "    return (\n",
    "        f\"**Author**: {creators}  \\n\"\n",
    "        f\"**Source**: {source_md}  \\n\"\n",
    "        f\"**Please cite**: https://archive.ics.uci.edu/ml/citation_policy.html  \\n\\n\"\n",
    "        f\"* Abstract:\\n\\n\"\n",
    "        f\"(Optional) Add a short abstract/description here.\\n\"\n",
    "    )\n",
    "\n",
    "def _split_numeric_categorical(features) -> Tuple[List[str], List[str]]:\n",
    "    num, cat = [], []\n",
    "    for f in features:\n",
    "        dt = (f.data_type or \"\").lower()\n",
    "        if dt in {\"numeric\", \"real\", \"integer\"}:\n",
    "            num.append(f.name)\n",
    "        elif dt in {\"nominal\", \"string\", \"date\"}:\n",
    "            cat.append(f.name)\n",
    "        else:\n",
    "            cat.append(f.name)  # conservative default\n",
    "    return num, cat\n",
    "\n",
    "def _ensure_dir(p: str | Path) -> Path:\n",
    "    p = Path(p)\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "\n",
    "# ============================ 1) Inspect suite attributes =====================\n",
    "def inspect_suite_attributes(suite_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given an OpenML suite (e.g., 'OpenML-CC18'), return a table of dataset-level attributes\n",
    "    available from OpenML for all datasets in that suite.\n",
    "    \"\"\"\n",
    "    suite = openml.study.get_suite(suite_name)\n",
    "    task_ids = suite.tasks\n",
    "    dids = [openml.tasks.get_task(tid, download_data=False).dataset_id for tid in task_ids]\n",
    "\n",
    "    meta = openml.datasets.list_datasets(data_id=dids, output_format=\"dataframe\")\n",
    "    cols = [\n",
    "        \"did\",\"name\",\"NumberOfInstances\",\"NumberOfFeatures\",\"NumberOfClasses\",\n",
    "        \"NumberOfNumericFeatures\",\"NumberOfSymbolicFeatures\",\n",
    "        \"MajorityClassSize\",\"MinorityClassSize\",\"PercentageOfMissingValues\",\"version\",\"status\"\n",
    "    ]\n",
    "    meta = _ensure_columns(meta, cols)\n",
    "    df = meta[cols].copy()\n",
    "    for c in cols[2:]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # Add what we can from dataset-level API (target, license, creator, url, desc lengths)\n",
    "    extra_rows: List[Dict[str, Any]] = []\n",
    "    for did in df[\"did\"]:\n",
    "        try:\n",
    "            ds = openml.datasets.get_dataset(int(did), download_data=False)\n",
    "            extra_rows.append({\n",
    "                \"did\": int(did),\n",
    "                \"default_target\": ds.default_target_attribute,\n",
    "                \"licence\": getattr(ds, \"licence\", None),\n",
    "                \"creator\": ds.creator if isinstance(ds.creator, str) else (\", \".join(ds.creator) if ds.creator else None),\n",
    "                \"citation\": getattr(ds, \"citation\", None),\n",
    "                \"original_data_url\": getattr(ds, \"original_data_url\", None),\n",
    "                \"description_len\": len(getattr(ds, \"description\", \"\") or \"\"),\n",
    "                \"n_features_declared\": len(ds.features) if getattr(ds, \"features\", None) else np.nan\n",
    "            })\n",
    "        except Exception:\n",
    "            extra_rows.append({\n",
    "                \"did\": int(did),\n",
    "                \"default_target\": None,\n",
    "                \"licence\": None,\n",
    "                \"creator\": None,\n",
    "                \"citation\": None,\n",
    "                \"original_data_url\": None,\n",
    "                \"description_len\": np.nan,\n",
    "                \"n_features_declared\": np.nan\n",
    "            })\n",
    "    extra = pd.DataFrame(extra_rows)\n",
    "\n",
    "    out = df.merge(extra, on=\"did\", how=\"left\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# ============================ 2) Selection (your criteria) ====================\n",
    "def build_selection_from_suite(suite_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Same selection logic you specified, applied to any OpenML suite,\n",
    "    but selecting up to TWO datasets each time instead of one.\n",
    "    \"\"\"\n",
    "    suite = openml.study.get_suite(suite_name)\n",
    "    task_ids = suite.tasks\n",
    "    dids = [openml.tasks.get_task(tid, download_data=False).dataset_id for tid in task_ids]\n",
    "\n",
    "    meta = openml.datasets.list_datasets(data_id=dids, output_format=\"dataframe\")\n",
    "    cols = [\n",
    "        \"did\",\"name\",\"NumberOfInstances\",\"NumberOfFeatures\",\"NumberOfClasses\",\n",
    "        \"NumberOfNumericFeatures\",\"NumberOfSymbolicFeatures\",\n",
    "        \"MajorityClassSize\",\"MinorityClassSize\",\"PercentageOfMissingValues\"\n",
    "    ]\n",
    "    meta = _ensure_columns(meta, cols)\n",
    "    df = meta[cols].copy()\n",
    "    for c in cols[2:]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    df[\"class_type\"] = np.where(df[\"NumberOfClasses\"] == 2, \"binary\", \"multiclass\")\n",
    "    df[\"size_bin\"] = pd.cut(\n",
    "        df[\"NumberOfInstances\"], bins=SIZE_BINS, labels=SIZE_LABELS,\n",
    "        right=True, include_lowest=True\n",
    "    )\n",
    "    den = (df[\"NumberOfSymbolicFeatures\"].fillna(0) + df[\"NumberOfNumericFeatures\"].fillna(0))\n",
    "    df[\"cat_frac\"] = (df[\"NumberOfSymbolicFeatures\"].fillna(0) / den.replace(0, np.nan)).fillna(0.0)\n",
    "    df[\"feature_mix\"] = np.where(df[\"cat_frac\"] >= CAT_FRAC_THRESHOLD, \"high_categorical\", \"high_numerical\")\n",
    "    df[\"missing_pct\"] = _safe_num(df[\"PercentageOfMissingValues\"]).fillna(0.0)\n",
    "\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        df[\"imbalance_ratio\"] = (df[\"MajorityClassSize\"] / df[\"MinorityClassSize\"]).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    selected_rows: list[pd.DataFrame] = []\n",
    "    selected_dids: set[int] = set()\n",
    "\n",
    "    # ---- modified helpers: return up to k rows instead of 1 ----\n",
    "    def _pick_max_features(candidates: pd.DataFrame, k: int = 2) -> pd.DataFrame | None:\n",
    "        if candidates.empty:\n",
    "            return None\n",
    "        c = candidates.copy()\n",
    "        c[\"NumberOfFeatures\"] = _safe_num(c[\"NumberOfFeatures\"]).fillna(-np.inf)\n",
    "        c[\"missing_pct\"] = _safe_num(c[\"PercentageOfMissingValues\"]).fillna(0.0)\n",
    "        maxF = c[\"NumberOfFeatures\"].max()\n",
    "        at_max = c[c[\"NumberOfFeatures\"] == maxF]\n",
    "        # sort by missing_pct then name, then take top-k\n",
    "        return at_max.sort_values([\"missing_pct\", \"name\"], ascending=[True, True]).head(k)\n",
    "\n",
    "    def _pick_centered(candidates: pd.DataFrame, fmix: str, k: int = 2) -> pd.DataFrame | None:\n",
    "        if candidates.empty:\n",
    "            return None\n",
    "        target_center = 0.6 if fmix == \"high_categorical\" else 0.0\n",
    "        cc = candidates.copy()\n",
    "        cc[\"missing_pct\"] = _safe_num(cc[\"PercentageOfMissingValues\"]).fillna(0.0)\n",
    "        cc = cc.assign(center_distance=(cc[\"cat_frac\"] - target_center).abs())\n",
    "        # sort by distance to target cat_frac, then missing_pct, then name; take top-k\n",
    "        return cc.sort_values(\n",
    "            [\"center_distance\", \"missing_pct\", \"name\"],\n",
    "            ascending=[True, True, True]\n",
    "        ).head(k)\n",
    "\n",
    "    def _avail(pool: pd.DataFrame) -> pd.DataFrame:\n",
    "        return pool[~pool[\"did\"].isin(selected_dids)]\n",
    "\n",
    "    cells = [(t, s) for t in [\"binary\", \"multiclass\"] for s in SIZE_LABELS]\n",
    "\n",
    "    for (task, size) in cells:\n",
    "        block = _avail(df[(df[\"class_type\"] == task) & (df[\"size_bin\"] == size)])\n",
    "        if block.empty:\n",
    "            continue\n",
    "\n",
    "        block_cat = block[block[\"feature_mix\"] == \"high_categorical\"]\n",
    "        block_num = block[block[\"feature_mix\"] == \"high_numerical\"]\n",
    "\n",
    "        # candidates for \"winner\" side (up to 2 each)\n",
    "        top_cat = _pick_max_features(block_cat, k=2) if not block_cat.empty else None\n",
    "        top_num = _pick_max_features(block_num, k=2) if not block_num.empty else None\n",
    "\n",
    "        # for deciding which mix wins, use the *first* row of each\n",
    "        max_cat = _safe_num(block_cat[\"NumberOfFeatures\"]).max() if not block_cat.empty else -np.inf\n",
    "        max_num = _safe_num(block_num[\"NumberOfFeatures\"]).max() if not block_num.empty else -np.inf\n",
    "\n",
    "        if max_cat > max_num:\n",
    "            winner_mix, winner_pick = \"high_categorical\", top_cat\n",
    "            loser_mix = \"high_numerical\"\n",
    "        elif max_num > max_cat:\n",
    "            winner_mix, winner_pick = \"high_numerical\", top_num\n",
    "            loser_mix = \"high_categorical\"\n",
    "        else:\n",
    "            if top_cat is None and top_num is None:\n",
    "                continue\n",
    "            elif top_cat is None:\n",
    "                winner_mix, winner_pick, loser_mix = \"high_numerical\", top_num, \"high_categorical\"\n",
    "            elif top_num is None:\n",
    "                winner_mix, winner_pick, loser_mix = \"high_categorical\", top_cat, \"high_numerical\"\n",
    "            else:\n",
    "                # compare the *best* candidate of each\n",
    "                c_row, n_row = top_cat.iloc[0], top_num.iloc[0]\n",
    "                if (c_row[\"missing_pct\"], c_row[\"name\"]) <= (n_row[\"missing_pct\"], n_row[\"name\"]):\n",
    "                    winner_mix, winner_pick, loser_mix = \"high_categorical\", top_cat, \"high_numerical\"\n",
    "                else:\n",
    "                    winner_mix, winner_pick, loser_mix = \"high_numerical\", top_num, \"high_categorical\"\n",
    "\n",
    "        # add up to TWO \"winner\" datasets\n",
    "        if winner_pick is not None and not winner_pick.empty:\n",
    "            selected_rows.append(winner_pick)\n",
    "            selected_dids.update(winner_pick[\"did\"].tolist())\n",
    "\n",
    "        # now recompute availability and pick up to TWO \"loser\" datasets\n",
    "        block = _avail(block)\n",
    "        loser_pool = block[block[\"feature_mix\"] == loser_mix]\n",
    "\n",
    "        loser_pick = _pick_centered(loser_pool, loser_mix, k=2)\n",
    "        if (loser_pick is None or loser_pick.empty) and not block.empty:\n",
    "            # fallback: centered within whole block\n",
    "            loser_pick = _pick_centered(block, loser_mix, k=2)\n",
    "\n",
    "        if loser_pick is not None and not loser_pick.empty:\n",
    "            selected_rows.append(loser_pick)\n",
    "            selected_dids.update(loser_pick[\"did\"].tolist())\n",
    "\n",
    "    sel = (\n",
    "        pd.concat(selected_rows, ignore_index=True)\n",
    "        .drop_duplicates(subset=[\"did\"])\n",
    "        .reset_index(drop=True)\n",
    "        if selected_rows else pd.DataFrame(columns=df.columns)\n",
    "    )\n",
    "\n",
    "    # Attach task_ids (traceability)\n",
    "    did_to_tasks = defaultdict(list)\n",
    "    for tid in task_ids:\n",
    "        t = openml.tasks.get_task(tid, download_data=False)\n",
    "        did_to_tasks[t.dataset_id].append(tid)\n",
    "    sel[\"task_ids\"] = sel[\"did\"].map(did_to_tasks)\n",
    "    return sel\n",
    "\n",
    "\n",
    "# ============================ 3) Save datasets + info.json ====================\n",
    "def save_selected_datasets(selection: pd.DataFrame, base_dir: str = \"./data\") -> pd.DataFrame:\n",
    "    records = []\n",
    "\n",
    "    for _, row in selection.iterrows():\n",
    "        did = int(row[\"did\"])\n",
    "        try:\n",
    "            ds = openml.datasets.get_dataset(did, download_data=True)\n",
    "            dataset_name = ds.name  # exact\n",
    "            dataset_name_path = _file_safe_exact(dataset_name)\n",
    "\n",
    "            target_name = ds.default_target_attribute\n",
    "            # IMPORTANT: use the categorical_indicator returned by get_data\n",
    "            X, y, categorical_indicator, attribute_names = ds.get_data(\n",
    "                dataset_format=\"dataframe\",\n",
    "                target=target_name if target_name else None\n",
    "            )\n",
    "\n",
    "            # --- robust feature typing using categorical_indicator ---\n",
    "            # categorical_indicator aligns with X.columns order\n",
    "            if categorical_indicator is None:\n",
    "                # very rare, fallback to \"object→cat, else numeric\"\n",
    "                cat_mask = [pd.api.types.is_object_dtype(X[c]) or pd.api.types.is_categorical_dtype(X[c])\n",
    "                            for c in X.columns]\n",
    "            else:\n",
    "                cat_mask = list(categorical_indicator)\n",
    "\n",
    "            cat_feats = [col for col, is_cat in zip(X.columns, cat_mask) if is_cat]\n",
    "            num_feats = [col for col, is_cat in zip(X.columns, cat_mask) if not is_cat]\n",
    "\n",
    "            # assemble dataframe to save\n",
    "            if y is not None:\n",
    "                # guard y name when target_name is None\n",
    "                y_name = target_name if isinstance(target_name, str) and len(target_name) else \"target\"\n",
    "                df_all = pd.concat([X, y.rename(y_name)], axis=1)\n",
    "            else:\n",
    "                df_all = X.copy()\n",
    "\n",
    "            # missingness\n",
    "            missing_cells = int(df_all.isna().sum().sum())\n",
    "            total_cells = int(df_all.shape[0] * df_all.shape[1]) if df_all.size else 0\n",
    "            missing_pct = float(missing_cells / total_cells) if total_cells > 0 else 0.0\n",
    "\n",
    "            n_num = len(num_feats)\n",
    "            n_cat = len(cat_feats)\n",
    "            n_features = n_num + n_cat\n",
    "            sample_size = int(df_all.shape[0])\n",
    "            cat_frac_est = float(n_cat / n_features) if n_features > 0 else 0.0\n",
    "\n",
    "            # classes / task type / imbalance\n",
    "            n_classes = int(row[\"NumberOfClasses\"]) if not pd.isna(row.get(\"NumberOfClasses\")) else None\n",
    "            if n_classes is None and y is not None and y.notna().any():\n",
    "                n_classes = int(y.nunique())\n",
    "\n",
    "            task_type = row.get(\"class_type\") if isinstance(row.get(\"class_type\"), str) else (\n",
    "                \"binary\" if (n_classes == 2) else \"multiclass\"\n",
    "            )\n",
    "            imbalance_ratio = None\n",
    "            if y is not None and task_type in {\"binary\", \"multiclass\"}:\n",
    "                vc = y.value_counts(dropna=False)\n",
    "                if len(vc) >= 2 and vc.min() > 0:\n",
    "                    imbalance_ratio = float(vc.max() / vc.min())\n",
    "\n",
    "            # URLs & intro\n",
    "            source_url = _openml_download_url_placeholder(did, dataset_name)\n",
    "            openml_page = _openml_page_url(did)\n",
    "            task_intro = _make_task_intro(ds, did, dataset_name)\n",
    "\n",
    "            # Output\n",
    "            out_dir = _ensure_dir(Path(base_dir) / task_type / dataset_name_path)\n",
    "            csv_path = out_dir / f\"{dataset_name_path}.csv\"\n",
    "            info_path = out_dir / \"info.json\"\n",
    "            df_all.to_csv(csv_path, index=False)\n",
    "\n",
    "            info = OrderedDict()\n",
    "            info[\"name\"] = dataset_name\n",
    "            info[\"n_num_features\"] = n_num\n",
    "            info[\"n_cat_features\"] = n_cat\n",
    "            info[\"sample_size\"] = sample_size\n",
    "            info[\"n_features\"] = n_features\n",
    "            info[\"cat_frac_est\"] = cat_frac_est\n",
    "            info[\"missing_cells_estimated_from_file\"] = missing_cells\n",
    "            info[\"missing_pct_estimated_from_file\"] = missing_pct\n",
    "            info[\"source\"] = source_url\n",
    "            info[\"openml_page\"] = openml_page\n",
    "            info[\"task_intro\"] = task_intro\n",
    "            info[\"task_type\"] = task_type\n",
    "            info[\"openml_id\"] = did\n",
    "            info[\"imbalance_ratio\"] = imbalance_ratio\n",
    "            info[\"n_classes\"] = n_classes\n",
    "            info[\"target_variable\"] = target_name if target_name else \"target\"\n",
    "            info[\"target_description\"] = None\n",
    "            info[\"num_feature_intro\"] = OrderedDict((f, \"numeric feature\") for f in num_feats)\n",
    "            info[\"cat_feature_intro\"] = OrderedDict((f, \"categorical feature\") for f in cat_feats)\n",
    "\n",
    "            with open(info_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(info, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "            records.append({\n",
    "                \"did\": did,\n",
    "                \"name\": dataset_name,\n",
    "                \"task_type\": task_type,\n",
    "                \"saved_csv\": str(csv_path),\n",
    "                \"saved_info\": str(info_path),\n",
    "            })\n",
    "            print(f\"Saved: {dataset_name} → {csv_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Skipped DID={did} due to error: {e}\")\n",
    "\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "\n",
    "# ============================ 4) Example run ==================================\n",
    "if __name__ == \"__main__\":\n",
    "    SUITE = \"OpenML-CC18\"  # change to any OpenML suite/collection name\n",
    "\n",
    "    print(\"Inspecting suite attributes...\")\n",
    "    suite_attrs = inspect_suite_attributes(SUITE)\n",
    "    print(suite_attrs.head(12).to_string(index=False))  # peek\n",
    "\n",
    "    print(\"\\nBuilding selection with your criteria...\")\n",
    "    sel = build_selection_from_suite(SUITE)\n",
    "    print(sel[[\"did\", \"name\", \"class_type\", \"size_bin\", \"feature_mix\"]].to_string(index=False))\n",
    "\n",
    "    print(\"\\nSaving selected datasets + info.json...\")\n",
    "    summary = save_selected_datasets(sel, base_dir=\"./data\")\n",
    "\n",
    "    print(\"\\nSummary of saved datasets:\")\n",
    "    if len(summary):\n",
    "        print(summary.to_string(index=False))\n",
    "    else:\n",
    "        print(\"(no datasets saved)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d155b4ab-7846-4e76-a1d3-dc62f7daa717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "\n",
    "# Binning only for labeling (no filtering)\n",
    "SIZE_BINS = [0, 2000, 10000, np.inf]\n",
    "SIZE_LABELS = [\"small\", \"medium\", \"large\"]\n",
    "CAT_FRAC_THRESHOLD = 0.5  # >= → high_categorical\n",
    "\n",
    "\n",
    "def build_ctr23_feature_winner_normal_loser_selection() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    CTR23 (regression suite, id=353) selector with *no caps*:\n",
    "      For each size_bin in [small, medium, large]:\n",
    "        1) Compare the *maximum NumberOfFeatures* available between the two mixes\n",
    "           (\"high_categorical\" vs \"high_numerical\") within that size bin.\n",
    "           The mix with the higher max is the *feature-winner* for that bin.\n",
    "        2) Pick up to TWO datasets from the winning mix:\n",
    "             - highest NumberOfFeatures (ties → lower missing_pct → name)\n",
    "        3) From the losing mix, pick up to TWO datasets using the centered mix rule:\n",
    "             - cat_frac closest to 0.6 (if high_categorical) or 0.0 (if high_numerical)\n",
    "             - ties → lower missing_pct → name\n",
    "        4) If a mix has no candidates in the size bin, fall back to the other mix\n",
    "           (still avoiding duplicates when possible), using the same tie-breakers.\n",
    "      Returns up to 12 datasets total (4 per size bin).\n",
    "    \"\"\"\n",
    "\n",
    "    # --- tiny helpers (scoped) ---\n",
    "    def _ensure_columns(df: pd.DataFrame, cols, fill=np.nan) -> pd.DataFrame:\n",
    "        for c in cols:\n",
    "            if c not in df.columns:\n",
    "                df[c] = fill\n",
    "        return df\n",
    "\n",
    "    def _safe_num(s: pd.Series) -> pd.Series:\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    # --- Load CTR23 task set (regression) ---\n",
    "    suite = openml.study.get_suite(353)  # CTR23\n",
    "    task_ids = suite.tasks\n",
    "    dids = [openml.tasks.get_task(tid, download_data=False).dataset_id for tid in task_ids]\n",
    "\n",
    "    # --- Pull dataset metadata ---\n",
    "    meta = openml.datasets.list_datasets(data_id=dids, output_format=\"dataframe\")\n",
    "    cols_wanted = [\n",
    "        \"did\", \"name\",\n",
    "        \"NumberOfInstances\", \"NumberOfFeatures\", \"NumberOfClasses\",\n",
    "        \"NumberOfNumericFeatures\", \"NumberOfSymbolicFeatures\",\n",
    "        \"PercentageOfMissingValues\"\n",
    "    ]\n",
    "    meta = _ensure_columns(meta, cols_wanted)\n",
    "    df = meta[cols_wanted].copy()\n",
    "\n",
    "    # numeric coercion\n",
    "    for c in cols_wanted[2:]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # task type label (CTR23 is regression; kept for consistency)\n",
    "    df[\"task_type\"] = \"regression\"\n",
    "\n",
    "    # size bins (no filtering)\n",
    "    df[\"size_bin\"] = pd.cut(\n",
    "        df[\"NumberOfInstances\"],\n",
    "        bins=SIZE_BINS,\n",
    "        labels=SIZE_LABELS,\n",
    "        right=True,\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "    # feature mix & cat fraction\n",
    "    den = df[\"NumberOfSymbolicFeatures\"].fillna(0) + df[\"NumberOfNumericFeatures\"].fillna(0)\n",
    "    df[\"cat_frac\"] = (df[\"NumberOfSymbolicFeatures\"].fillna(0) / den.replace(0, np.nan)).fillna(0.0)\n",
    "    df[\"feature_mix\"] = np.where(df[\"cat_frac\"] >= CAT_FRAC_THRESHOLD, \"high_categorical\", \"high_numerical\")\n",
    "\n",
    "    # missingness (percentage)\n",
    "    df[\"missing_pct\"] = _safe_num(df[\"PercentageOfMissingValues\"]).fillna(0.0)\n",
    "\n",
    "    # helper to avoid reusing the same DID\n",
    "    selected_rows = []\n",
    "    selected_dids = set()\n",
    "\n",
    "    def avail(pool: pd.DataFrame) -> pd.DataFrame:\n",
    "        return pool[~pool[\"did\"].isin(selected_dids)]\n",
    "\n",
    "    # tie-break helpers (now with k)\n",
    "    def pick_max_features(candidates: pd.DataFrame, k: int = 2) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Top-k by NumberOfFeatures desc (we filter by max first),\n",
    "        then missing_pct asc, then name asc.\n",
    "        Returns a DataFrame with up to k rows.\n",
    "        \"\"\"\n",
    "        if candidates is None or candidates.empty:\n",
    "            return None\n",
    "        maxF = candidates[\"NumberOfFeatures\"].max()\n",
    "        at_max = candidates[candidates[\"NumberOfFeatures\"] == maxF]\n",
    "        return at_max.sort_values([\"missing_pct\", \"name\"], ascending=[True, True]).head(k)\n",
    "\n",
    "    def pick_centered(candidates: pd.DataFrame, fmix: str, k: int = 2) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Centered mix rule:\n",
    "          - target cat_frac = 0.6 if high_categorical, else 0.0\n",
    "          - sort by |cat_frac - target|, then missing_pct, then name\n",
    "        Returns up to k rows.\n",
    "        \"\"\"\n",
    "        if candidates is None or candidates.empty:\n",
    "            return None\n",
    "        target = 0.6 if fmix == \"high_categorical\" else 0.0\n",
    "        cc = candidates.copy()\n",
    "        cc[\"center_distance\"] = (cc[\"cat_frac\"] - target).abs()\n",
    "        return cc.sort_values(\n",
    "            [\"center_distance\", \"missing_pct\", \"name\"],\n",
    "            ascending=[True, True, True]\n",
    "        ).head(k)\n",
    "\n",
    "    # Iterate each size bin\n",
    "    for size in SIZE_LABELS:\n",
    "        block = avail(df[df[\"size_bin\"] == size])\n",
    "        if block.empty:\n",
    "            continue\n",
    "\n",
    "        # Split by mix within this size bin\n",
    "        block_cat = block[block[\"feature_mix\"] == \"high_categorical\"]\n",
    "        block_num = block[block[\"feature_mix\"] == \"high_numerical\"]\n",
    "\n",
    "        # Determine max features per mix\n",
    "        max_cat = block_cat[\"NumberOfFeatures\"].max() if not block_cat.empty else -np.inf\n",
    "        max_num = block_num[\"NumberOfFeatures\"].max() if not block_num.empty else -np.inf\n",
    "\n",
    "        # Precompute the \"max-features\" picks (up to 2) for both mixes\n",
    "        top_cat = pick_max_features(block_cat, k=2) if not block_cat.empty else None\n",
    "        top_num = pick_max_features(block_num, k=2) if not block_num.empty else None\n",
    "\n",
    "        # Choose winner mix with deterministic tie-break (based on best candidate of each)\n",
    "        if max_cat > max_num:\n",
    "            winner_mix, loser_mix = \"high_categorical\", \"high_numerical\"\n",
    "            winner_pick, loser_pool = top_cat, block_num\n",
    "        elif max_num > max_cat:\n",
    "            winner_mix, loser_mix = \"high_numerical\", \"high_categorical\"\n",
    "            winner_pick, loser_pool = top_num, block_cat\n",
    "        else:\n",
    "            # Tie on max features\n",
    "            if top_cat is None and top_num is None:\n",
    "                continue\n",
    "            elif top_cat is None:\n",
    "                winner_mix, loser_mix = \"high_numerical\", \"high_categorical\"\n",
    "                winner_pick, loser_pool = top_num, block_cat\n",
    "            elif top_num is None:\n",
    "                winner_mix, loser_mix = \"high_categorical\", \"high_numerical\"\n",
    "                winner_pick, loser_pool = top_cat, block_num\n",
    "            else:\n",
    "                # Both exist; compare their best (first) candidates\n",
    "                c_row = top_cat.iloc[0]\n",
    "                n_row = top_num.iloc[0]\n",
    "                cat_key = (c_row[\"missing_pct\"], c_row[\"name\"])\n",
    "                num_key = (n_row[\"missing_pct\"], n_row[\"name\"])\n",
    "                if cat_key <= num_key:\n",
    "                    winner_mix, loser_mix = \"high_categorical\", \"high_numerical\"\n",
    "                    winner_pick, loser_pool = top_cat, block_num\n",
    "                else:\n",
    "                    winner_mix, loser_mix = \"high_numerical\", \"high_categorical\"\n",
    "                    winner_pick, loser_pool = top_num, block_cat\n",
    "\n",
    "        # 1) Add up to TWO winners (max-features within its mix)\n",
    "        if winner_pick is not None and not winner_pick.empty:\n",
    "            selected_rows.append(winner_pick)\n",
    "            selected_dids.update(winner_pick[\"did\"].tolist())\n",
    "\n",
    "        # 2) Add up to TWO losers using *centered mix* rule\n",
    "        loser_pool = avail(loser_pool)  # exclude any just-selected DIDs\n",
    "        loser_pick = pick_centered(loser_pool, loser_mix, k=2)\n",
    "\n",
    "        if loser_pick is not None and not loser_pick.empty:\n",
    "            selected_rows.append(loser_pick)\n",
    "            selected_dids.update(loser_pick[\"did\"].tolist())\n",
    "        else:\n",
    "            # Fallback: centered from the whole size-bin block\n",
    "            fallback_pool = avail(block)\n",
    "            fallback_pick = pick_centered(fallback_pool, loser_mix, k=2)\n",
    "            if fallback_pick is not None and not fallback_pick.empty:\n",
    "                selected_rows.append(fallback_pick)\n",
    "                selected_dids.update(fallback_pick[\"did\"].tolist())\n",
    "\n",
    "    # --- Build selection DF ---\n",
    "    if selected_rows:\n",
    "        sel = (\n",
    "            pd.concat(selected_rows, ignore_index=True)\n",
    "            .drop_duplicates(subset=[\"did\"])\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "    else:\n",
    "        sel = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    # Map did -> CTR23 task IDs (collect all tasks per DID)\n",
    "    did_to_tasks = defaultdict(list)\n",
    "    for tid in task_ids:\n",
    "        task = openml.tasks.get_task(tid, download_data=False)\n",
    "        did_to_tasks[task.dataset_id].append(tid)\n",
    "    sel[\"task_ids\"] = sel[\"did\"].map(did_to_tasks)\n",
    "\n",
    "    # Sort for readability\n",
    "    sel = sel.sort_values([\"size_bin\", \"feature_mix\", \"name\"]).reset_index(drop=True)\n",
    "    return sel\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    BASE_DIR = \"./data\"\n",
    "\n",
    "    print(\"Building CTR23 selection (feature-winner + centered-loser, 2+2 per size bin)...\")\n",
    "    sel = build_ctr23_feature_winner_normal_loser_selection()\n",
    "    print(\"\\nSelected datasets:\")\n",
    "    print(sel[[\"did\", \"name\", \"size_bin\", \"feature_mix\", \"cat_frac\"]].to_string(index=False))\n",
    "\n",
    "    print(\"\\nSaving selected datasets + info.json...\")\n",
    "    summary = save_selected_datasets(sel, base_dir=BASE_DIR)\n",
    "\n",
    "    print(\"\\nSummary of saved datasets:\")\n",
    "    if len(summary):\n",
    "        print(summary.to_string(index=False))\n",
    "    else:\n",
    "        print(\"(no datasets saved)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff3d08-17de-4d0b-9478-32473df5a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "# --- Configuration ---\n",
    "SIZE_BINS = [0, 2000, 10000, np.inf]\n",
    "SIZE_LABELS = [\"small\", \"medium\", \"large\"]\n",
    "CAT_FRAC_THRESHOLD = 0.6  # >= → high_categorical (match your main script)\n",
    "DELAY_SECONDS = 3         # delay between OpenML calls to avoid overload\n",
    "\n",
    "\n",
    "def build_suite_all_datasets_selection(\n",
    "    suite_name: str,\n",
    "    delay: int = DELAY_SECONDS\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return ALL datasets in a given OpenML suite (e.g. 'OpenML-CC18'),\n",
    "    with delay between OpenML API calls to avoid overloading the server.\n",
    "\n",
    "    Adds handy extra columns:\n",
    "      - class_type (binary / multiclass from NumberOfClasses)\n",
    "      - size_bin (small / medium / large)\n",
    "      - cat_frac, feature_mix (high_categorical / high_numerical)\n",
    "      - missing_pct\n",
    "      - task_ids (list of OpenML task IDs using that dataset)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- tiny helpers (scoped) ---\n",
    "    def _ensure_columns(df: pd.DataFrame, cols, fill=np.nan) -> pd.DataFrame:\n",
    "        for c in cols:\n",
    "            if c not in df.columns:\n",
    "                df[c] = fill\n",
    "        return df\n",
    "\n",
    "    def _safe_num(s: pd.Series) -> pd.Series:\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    # --- Load suite & tasks ---\n",
    "    print(f\"Fetching suite metadata from OpenML: {suite_name!r} ...\")\n",
    "    suite = openml.study.get_suite(suite_name)\n",
    "    task_ids = suite.tasks\n",
    "    print(f\"Loaded suite with {len(task_ids)} tasks. Fetching dataset IDs...\")\n",
    "\n",
    "    dids: list[int] = []\n",
    "    for i, tid in enumerate(task_ids, 1):\n",
    "        task = openml.tasks.get_task(tid, download_data=False)\n",
    "        dids.append(task.dataset_id)\n",
    "        print(f\"  [{i}/{len(task_ids)}] Got task {tid} → dataset {task.dataset_id}\")\n",
    "        time.sleep(delay)  # throttle requests\n",
    "\n",
    "    # --- Pull dataset metadata for ALL dids ---\n",
    "    print(\"Downloading dataset metadata table...\")\n",
    "    meta = openml.datasets.list_datasets(data_id=dids, output_format=\"dataframe\")\n",
    "    cols_wanted = [\n",
    "        \"did\", \"name\",\n",
    "        \"NumberOfInstances\", \"NumberOfFeatures\", \"NumberOfClasses\",\n",
    "        \"NumberOfNumericFeatures\", \"NumberOfSymbolicFeatures\",\n",
    "        \"MajorityClassSize\", \"MinorityClassSize\",\n",
    "        \"PercentageOfMissingValues\",\n",
    "    ]\n",
    "    meta = _ensure_columns(meta, cols_wanted)\n",
    "    df = meta[cols_wanted].copy()\n",
    "\n",
    "    # numeric coercion\n",
    "    for c in cols_wanted[2:]:\n",
    "        df[c] = _safe_num(df[c])\n",
    "\n",
    "    # class_type from NumberOfClasses (used by your saver)\n",
    "    df[\"class_type\"] = np.where(df[\"NumberOfClasses\"] == 2, \"binary\", \"multiclass\")\n",
    "\n",
    "    # size bins\n",
    "    df[\"size_bin\"] = pd.cut(\n",
    "        df[\"NumberOfInstances\"],\n",
    "        bins=SIZE_BINS,\n",
    "        labels=SIZE_LABELS,\n",
    "        right=True,\n",
    "        include_lowest=True,\n",
    "    )\n",
    "\n",
    "    # feature mix & cat fraction\n",
    "    den = df[\"NumberOfSymbolicFeatures\"].fillna(0) + df[\"NumberOfNumericFeatures\"].fillna(0)\n",
    "    df[\"cat_frac\"] = (\n",
    "        df[\"NumberOfSymbolicFeatures\"].fillna(0) / den.replace(0, np.nan)\n",
    "    ).fillna(0.0)\n",
    "    df[\"feature_mix\"] = np.where(\n",
    "        df[\"cat_frac\"] >= CAT_FRAC_THRESHOLD,\n",
    "        \"high_categorical\",\n",
    "        \"high_numerical\",\n",
    "    )\n",
    "\n",
    "    # missingness\n",
    "    df[\"missing_pct\"] = _safe_num(df[\"PercentageOfMissingValues\"]).fillna(0.0)\n",
    "\n",
    "    # imbalance ratio (if sizes available)\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        df[\"imbalance_ratio\"] = (\n",
    "            df[\"MajorityClassSize\"] / df[\"MinorityClassSize\"]\n",
    "        ).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Map did -> suite task IDs (collect all tasks per DID)\n",
    "    print(\"Mapping dataset IDs to their corresponding tasks...\")\n",
    "    did_to_tasks = defaultdict(list)\n",
    "    for i, tid in enumerate(task_ids, 1):\n",
    "        task = openml.tasks.get_task(tid, download_data=False)\n",
    "        did_to_tasks[task.dataset_id].append(tid)\n",
    "        print(f\"  [{i}/{len(task_ids)}] Linked task {tid}\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    df[\"task_ids\"] = df[\"did\"].map(did_to_tasks)\n",
    "\n",
    "    df = df.sort_values([\"class_type\", \"size_bin\", \"feature_mix\", \"name\"]).reset_index(drop=True)\n",
    "    print(f\"\\n✅ Finished collecting suite {suite_name!r} datasets: {len(df)} total.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================ Example run =====================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    SUITE = \"OpenML-CC18\"   # or any other suite name\n",
    "    BASE_DIR = \"./data\"\n",
    "\n",
    "    print(f\"Building {SUITE} selection with ALL datasets (delayed mode)...\")\n",
    "    sel = build_suite_all_datasets_selection(SUITE, delay=DELAY_SECONDS)\n",
    "\n",
    "    print(\"\\nSelected datasets (all in suite):\")\n",
    "    print(sel[[\"did\", \"name\", \"class_type\", \"size_bin\", \"feature_mix\", \"cat_frac\"]].to_string(index=False))\n",
    "\n",
    "    print(\"\\nSaving selected datasets + info.json...\")\n",
    "    summary = save_selected_datasets(sel, base_dir=BASE_DIR)\n",
    "\n",
    "    print(\"\\nSummary of saved datasets:\")\n",
    "    if len(summary):\n",
    "        print(summary.to_string(index=False))\n",
    "    else:\n",
    "        print(\"(no datasets saved)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fc864-7c70-4f8c-8c12-3139cbdcd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "# --- Configuration ---\n",
    "SIZE_BINS = [0, 2000, 10000, np.inf]\n",
    "SIZE_LABELS = [\"small\", \"medium\", \"large\"]\n",
    "CAT_FRAC_THRESHOLD = 0.5\n",
    "DELAY_SECONDS = 3  # delay between OpenML calls to avoid overload\n",
    "\n",
    "\n",
    "def build_ctr23_all_datasets_selection(delay: int = DELAY_SECONDS) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return ALL datasets in CTR23 (regression suite, id=353),\n",
    "    with delay between OpenML API calls to avoid overloading the server.\n",
    "    \"\"\"\n",
    "    def _ensure_columns(df: pd.DataFrame, cols, fill=np.nan) -> pd.DataFrame:\n",
    "        for c in cols:\n",
    "            if c not in df.columns:\n",
    "                df[c] = fill\n",
    "        return df\n",
    "\n",
    "    def _safe_num(s: pd.Series) -> pd.Series:\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    # --- Load CTR23 task set (regression) ---\n",
    "    print(\"Fetching CTR23 suite metadata from OpenML...\")\n",
    "    suite = openml.study.get_suite(353)\n",
    "    task_ids = suite.tasks\n",
    "    print(f\"Loaded suite with {len(task_ids)} tasks. Fetching dataset IDs...\")\n",
    "\n",
    "    dids = []\n",
    "    for i, tid in enumerate(task_ids, 1):\n",
    "        task = openml.tasks.get_task(tid, download_data=False)\n",
    "        dids.append(task.dataset_id)\n",
    "        print(f\"  [{i}/{len(task_ids)}] Got task {tid} → dataset {task.dataset_id}\")\n",
    "        time.sleep(delay)  # prevent hammering the API\n",
    "\n",
    "    # --- Pull dataset metadata for ALL dids ---\n",
    "    print(\"Downloading dataset metadata table...\")\n",
    "    meta = openml.datasets.list_datasets(data_id=dids, output_format=\"dataframe\")\n",
    "    cols_wanted = [\n",
    "        \"did\", \"name\",\n",
    "        \"NumberOfInstances\", \"NumberOfFeatures\", \"NumberOfClasses\",\n",
    "        \"NumberOfNumericFeatures\", \"NumberOfSymbolicFeatures\",\n",
    "        \"PercentageOfMissingValues\"\n",
    "    ]\n",
    "    meta = _ensure_columns(meta, cols_wanted)\n",
    "    df = meta[cols_wanted].copy()\n",
    "\n",
    "    # numeric coercion\n",
    "    for c in cols_wanted[2:]:\n",
    "        df[c] = _safe_num(df[c])\n",
    "\n",
    "    # CTR23 is regression\n",
    "    df[\"task_type\"] = \"regression\"\n",
    "\n",
    "    # size bins (for inspection)\n",
    "    df[\"size_bin\"] = pd.cut(\n",
    "        df[\"NumberOfInstances\"],\n",
    "        bins=SIZE_BINS,\n",
    "        labels=SIZE_LABELS,\n",
    "        right=True,\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "    # feature mix & cat fraction\n",
    "    den = df[\"NumberOfSymbolicFeatures\"].fillna(0) + df[\"NumberOfNumericFeatures\"].fillna(0)\n",
    "    df[\"cat_frac\"] = (df[\"NumberOfSymbolicFeatures\"].fillna(0) / den.replace(0, np.nan)).fillna(0.0)\n",
    "    df[\"feature_mix\"] = np.where(df[\"cat_frac\"] >= CAT_FRAC_THRESHOLD,\n",
    "                                 \"high_categorical\", \"high_numerical\")\n",
    "\n",
    "    # missingness\n",
    "    df[\"missing_pct\"] = _safe_num(df[\"PercentageOfMissingValues\"]).fillna(0.0)\n",
    "\n",
    "    # Map did -> CTR23 task IDs (collect all tasks per DID)\n",
    "    print(\"Mapping dataset IDs to their corresponding tasks...\")\n",
    "    did_to_tasks = defaultdict(list)\n",
    "    for i, tid in enumerate(task_ids, 1):\n",
    "        task = openml.tasks.get_task(tid, download_data=False)\n",
    "        did_to_tasks[task.dataset_id].append(tid)\n",
    "        print(f\"  [{i}/{len(task_ids)}] Linked task {tid}\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "    df[\"task_ids\"] = df[\"did\"].map(did_to_tasks)\n",
    "\n",
    "    df = df.sort_values([\"size_bin\", \"feature_mix\", \"name\"]).reset_index(drop=True)\n",
    "    print(f\"\\n✅ Finished collecting CTR23 datasets: {len(df)} total.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================ Example run =====================================\n",
    "if __name__ == \"__main__\":\n",
    "    BASE_DIR = \"./data\"\n",
    "\n",
    "    print(\"Building CTR23 selection with ALL datasets (delayed mode)...\")\n",
    "    sel = build_ctr23_all_datasets_selection(delay=3)\n",
    "    print(\"\\nSelected datasets (all CTR23):\")\n",
    "    print(sel[[\"did\", \"name\", \"size_bin\", \"feature_mix\", \"cat_frac\"]].to_string(index=False))\n",
    "\n",
    "    print(\"\\nSaving selected datasets + info.json...\")\n",
    "    summary = save_selected_datasets(sel, base_dir=BASE_DIR)\n",
    "\n",
    "    print(\"\\nSummary of saved datasets:\")\n",
    "    if len(summary):\n",
    "        print(summary.to_string(index=False))\n",
    "    else:\n",
    "        print(\"(no datasets saved)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
